accelerate launch --use_deepspeed --deepspeed_config_file deepspeed_configs/deepspeed_zero2.json --mixed_precision bf16 --num_processes 4 --num_machines 1 seq2seq.py \
--mixed_precision bf16 \
--constrained_generation \
--constrained_generation \
--train_tsvs examples/conll/en.conll.train.tsv \
--dev_tsvs examples/conll/en.conll.dev.tsv \
--test_tsvs examples/conll/en.conll.test.tsv \
--num_beams 1 \
--num_return_sequences 1 \
--model_name_or_path google/gemma-2b-it \
--per_device_train_batch_size 2 \
--gradient_accumulation_steps 2 \
--per_device_eval_batch_size 2 \
--learning_rate 0.00007 \
--optim adamw \
--lr_scheduler_type cosine \
--num_warmup_steps 500 \
--num_train_epochs 30 \
--eval_every_epochs 5 \
--max_source_length 256 \
--max_target_length 256 \
--output_dir results/conll/FlanT5large \
--project_name SeqLabeling_w_LLMs \
--add_labels_as_tokens

